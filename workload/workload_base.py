# WorkloadåŸºç¡€ç±» - å¯¹åº”Workload.cc/Workload.hhä¸­çš„åŸºç¡€éƒ¨åˆ†
# å¯¹åº”C++å‡½æ•°ç­¾åï¼š
# - Workload::Workload(std::string run_name, Sys* generator, std::string name, int TOTAL_PASS, int total_rows, int stat_row, std::string path, bool seprate_log)
# - Workload::~Workload()
# - void Workload::call(EventType event, CallData* data)
# - void Workload::fire()
# - void Workload::check_for_sim_end()

from typing import List, Dict, Any, Optional, Tuple
import os
import sys

from system.callable import Callable, CallData
from system.common import EventType, ComType, SchedulingPolicy, CollectiveBarrier, Tick
from system.api import AstraSimDataAPI
from .parallelism_policy import ParallelismPolicy, LoopState
from .layer import Layer
from .csv_writer import CSVWriter
from .workload_parser import WorkloadParser
from .workload_iterators import WorkloadIterators
from .workload_reporting import WorkloadReporting


class Workload(Callable):
    """å·¥ä½œè´Ÿè½½ç±» - å¯¹åº”C++ç‰ˆæœ¬çš„Workloadç±»"""
    
    def __init__(self, run_name: str, generator, name: str, total_pass: int, 
                total_rows: int, stat_row: int, path: str, separate_log: bool):
        """
        åˆå§‹åŒ–å·¥ä½œè´Ÿè½½ - å¯¹åº”C++æ„é€ å‡½æ•°
        Workload::Workload(std::string run_name, Sys* generator, std::string name, int TOTAL_PASS, int total_rows, int stat_row, std::string path, bool seprate_log)
        
        Args:
            run_name: è¿è¡Œåç§°
            generator: ç³»ç»Ÿç”Ÿæˆå™¨
            name: å·¥ä½œè´Ÿè½½æ–‡ä»¶å
            total_pass: æ€»è½®æ¬¡
            total_rows: æ€»è¡Œæ•°
            stat_row: ç»Ÿè®¡è¡Œæ•°
            path: è¾“å‡ºè·¯å¾„
            separate_log: æ˜¯å¦åˆ†ç¦»æ—¥å¿—
        """
        super().__init__()
        
        # åŸºæœ¬å±æ€§
        self.initialized = False
        self.layers = []
        self.size = 0
        self.counter = 0
        self.delay_loaded = False
        self.checkpoint_initiated = False
        self.collective_issued = False
        self.current_state = LoopState.Forward_Pass
        self.generator = generator
        self.total_pass = total_pass
        self.pass_counter = 0
        self.index = 0
        self.waiting_for_comm = 0
        
        # DLRMç‰¹å®šå‚æ•°
        self.dlrm_last_bottom_layer = 0
        
        # Transformerç‰¹å®šå‚æ•°
        self.model_parallel_npu_group = 0  # TP Size
        self.expert_parallel_npu_group = 0  # Ep Size
        self.pipeline_model_parallelism = 0  # PP Size
        self.ga = 0  # Ga_Size
        self.all_gpus = 0
        self.vpp = 0
        self.pp_commsize = 0
        
        # æ£€æŸ¥ç‚¹æœºåˆ¶
        self.checkpoints = {}
        self.need_checkpoint_initiation = {}
        
        # è¿è¡Œç±»å‹
        self.run_type = ""
        
        # å¾…å¤„ç†çš„é›†ä½“é€šä¿¡æ•°é‡
        self.pending_collectives = 0
        
        # CSVå†™å…¥å™¨
        self.detailed = None
        self.end_to_end = None
        self.dimension_utilization = None
        
        # è·¯å¾„å’Œæ—¥å¿—è®¾ç½®
        self.path = path
        self.stat_row = stat_row
        self.separate_log = separate_log
        
        # åˆå§‹åŒ–å·¥ä½œè´Ÿè½½
        parser = WorkloadParser()
        self.initialized = parser.initialize_workload(self, name)
        if not self.initialized:
            return
            
        # æ·»åŠ å·¥ä½œè´Ÿè½½åˆå§‹åŒ–å®Œæˆæ—¥å¿—
        from system.mock_nccl_log import MockNcclLog, NcclLogLevel
        log = MockNcclLog.getInstance()
        log.writeLog(NcclLogLevel.INFO, f"å·¥ä½œè´Ÿè½½åˆå§‹åŒ–å®Œæˆ - ç±»å‹: {self.run_type}, å±‚æ•°: {self.size}, æ€»è½®æ¬¡: {total_pass}")
        log.writeLog(NcclLogLevel.INFO, f"å¹¶è¡Œç­–ç•¥: {self.parallelism_policy}, æ£€æŸ¥ç‚¹æ•°: {len(self.checkpoints)}")
            
        self.total_rows = total_rows
        self.run_name = run_name
        self.registered_for_finished_streams = False
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ–‡ä»¶
        if generator.id == 0 and separate_log:
            print(f"stat path: {path}, total rows: {total_rows}, stat row: {stat_row}")
            self.detailed = CSVWriter(path, f"detailed_{generator.total_nodes}.csv")
            self.end_to_end = CSVWriter(path, "EndToEnd.csv")
            self.dimension_utilization = CSVWriter(
                path, f"{run_name}_dimension_utilization_{generator.npu_offset}.csv")
            if stat_row == 0:
                self.initialize_stat_files()
        
        # åˆå§‹åŒ–è¿­ä»£å™¨å’ŒæŠ¥å‘Šå™¨
        self.iterators = WorkloadIterators(self)
        self.reporting = WorkloadReporting(self)
    
    def __del__(self):
        """
        ææ„å‡½æ•° - å¯¹åº”C++ææ„å‡½æ•°
        Workload::~Workload()
        """
        # æ˜¾å¼å…³é—­CSVæ–‡ä»¶
        if hasattr(self, 'end_to_end') and self.end_to_end:
            self.end_to_end.close()
            del self.end_to_end
        if hasattr(self, 'detailed') and self.detailed:
            self.detailed.close()
            del self.detailed
        if hasattr(self, 'dimension_utilization') and self.dimension_utilization:
            self.dimension_utilization.close()
            del self.dimension_utilization
        for layer in self.layers:
            del layer
    
    def initialize_stat_files(self):
        """
        åˆå§‹åŒ–ç»Ÿè®¡æ–‡ä»¶ - å¯¹åº”C++å‡½æ•°
        void Workload::initialize_stat_files()
        """
        self.detailed.initialize_csv(self.size * self.total_rows + 20, 50)
        self.end_to_end.initialize_csv(self.size * self.total_rows + 20, 50)
    
    def fire(self):
        """
        å¯åŠ¨å·¥ä½œè´Ÿè½½ - å¯¹åº”C++å‡½æ•°
        void Workload::fire()
        """
        from system.mock_nccl_log import MockNcclLog, NcclLogLevel
        log = MockNcclLog.getInstance()
        log.writeLog(NcclLogLevel.INFO, f"å¯åŠ¨å·¥ä½œè´Ÿè½½æ‰§è¡Œ - å½“å‰çŠ¶æ€: {self.current_state}, ç´¢å¼•: {self.index}")
        self.call(EventType.General, None)
    
    def call(self, event_type: EventType, data: CallData) -> None:
        """
        å¤„ç†å·¥ä½œè´Ÿè½½äº‹ä»¶ - å¯¹åº”C++å‡½æ•°
        void Workload::call(EventType event, CallData* mdata)
        
        Args:
            event_type: äº‹ä»¶ç±»å‹
            data: äº‹ä»¶æ•°æ®
        """
        from system.mock_nccl_log import MockNcclLog, NcclLogLevel
        log = MockNcclLog.getInstance()
        log.writeLog(NcclLogLevel.INFO, f"å·¥ä½œè´Ÿè½½æ¥æ”¶äº‹ä»¶: {event_type}, counter: {self.counter}")
        
        # å…³é”®ä¿®å¤ï¼šå¯¹åº”C++ç‰ˆæœ¬çš„é€»è¾‘ - é¦–å…ˆæ£€æŸ¥counter
        if self.counter > 0:
            log.writeLog(NcclLogLevel.INFO, f"counter > 0ï¼Œæ³¨å†Œç­‰å¾…äº‹ä»¶: {self.counter}")
            # è°ƒç”¨try_register_eventï¼Œå¹¶æ ¹æ®è¿”å›å€¼å†³å®šæ˜¯å¦æ¸…é›¶counter
            should_clear = self.generator.try_register_event(self, EventType.Workload_Wait, None, self.counter)
            if should_clear:
                # æ¨¡æ‹ŸC++ç‰ˆæœ¬çš„å¼•ç”¨ä¼ é€’æ•ˆæœï¼šcycles = 0
                self.counter = 0
                log.writeLog(NcclLogLevel.INFO, f"counterå·²æ¸…é›¶ï¼Œæ¨¡æ‹ŸC++ç‰ˆæœ¬çš„å¼•ç”¨ä¼ é€’æ•ˆæœ")
            return
        
        # counter == 0ï¼Œæ‰§è¡Œå®é™…çš„è¿­ä»£é€»è¾‘
        log.writeLog(NcclLogLevel.INFO, f"å¤„ç†äº‹ä»¶ - è°ƒç”¨è¿­ä»£å™¨")
        # æ ¹æ®å¹¶è¡Œç­–ç•¥è°ƒç”¨ç›¸åº”çš„è¿­ä»£æ–¹æ³•
        if self.parallelism_policy == ParallelismPolicy.MicroBenchmark:
            self.iterators.iterate_micro_benchmark()
        elif self.parallelism_policy == ParallelismPolicy.Data:
            self.iterators.iterate_data_parallel()
        elif self.parallelism_policy == ParallelismPolicy.TransformerFwdInBckwd:
            self.iterators.iterate_hybrid_parallel_transformer_fwd_in_bckwd()
        elif self.parallelism_policy == ParallelismPolicy.Transformer:
            self.iterators.iterate_hybrid_parallel_transformer()
        elif self.parallelism_policy == ParallelismPolicy.DLRM:
            self.iterators.iterate_hybrid_parallel_dlrm()
        elif self.parallelism_policy == ParallelismPolicy.Model:
            self.iterators.iterate_model_parallel()
        elif self.parallelism_policy == ParallelismPolicy.HybridDataModel:
            self.iterators.iterate_hybrid_parallel_data_model()
        elif self.parallelism_policy == ParallelismPolicy.HybridModelData:
            self.iterators.iterate_hybrid_parallel_model_data()
        elif self.parallelism_policy == ParallelismPolicy.DistributedInference:
            self.iterators.iterate_distributed_inference()
        elif self.parallelism_policy == ParallelismPolicy.HybridCustomized:
            self.iterators.iterate_hybrid_parallel_customized()
        else:
            log.writeLog(NcclLogLevel.ERROR, f"æœªæ”¯æŒçš„å¹¶è¡Œç­–ç•¥: {self.parallelism_policy}")
    
    def check_for_sim_end(self):
        """
        æ£€æŸ¥ä»¿çœŸæ˜¯å¦ç»“æŸ - å¯¹åº”C++å‡½æ•°
        void Workload::check_for_sim_end()
        """
        from system.mock_nccl_log import MockNcclLog, NcclLogLevel
        log = MockNcclLog.getInstance()
        
        log.writeLog(NcclLogLevel.INFO, f"ğŸ” check_for_sim_end: pass_counter={self.pass_counter}, total_pass={self.total_pass}")
        
        if self.pass_counter == self.total_pass:
            log.writeLog(NcclLogLevel.INFO, f"âœ… è¾¾åˆ°æ€»è½®æ¬¡ï¼Œè®¾ç½®çŠ¶æ€ä¸ºWait_For_Sim_Finish")
            self.current_state = LoopState.Wait_For_Sim_Finish
            
            log.writeLog(NcclLogLevel.INFO, f"ğŸ” streamsçŠ¶æ€: finished={self.generator.streams_finished}, injected={self.generator.streams_injected}")
            
            if (self.generator.streams_finished != self.generator.streams_injected and
                not self.registered_for_finished_streams):
                log.writeLog(NcclLogLevel.INFO, f"â³ ç­‰å¾…æµå®Œæˆï¼Œæ³¨å†Œç›‘å¬å™¨")
                self.generator.register_for_finished_stream(self)
                self.registered_for_finished_streams = True
                self.layers[0].is_weight_grad_comm_finished_blocking()
                return
            
            if self.generator.streams_finished == self.generator.streams_injected:
                log.writeLog(NcclLogLevel.INFO, f"ğŸ‰ æµå·²å®Œæˆï¼Œå¼€å§‹ç”ŸæˆæŠ¥å‘Š")
                if self.generator.id == 0:
                    self.reporting.report()
                self.generator.workload_finished()
                return
    
    @staticmethod
    def get_layer_numbers(workload_input: str) -> int:
        """
        è·å–å±‚æ•° - å¯¹åº”C++é™æ€å‡½æ•°
        static int Workload::get_layer_numbers(std::string workload_input)
        
        Args:
            workload_input: å·¥ä½œè´Ÿè½½è¾“å…¥æ–‡ä»¶å
            
        Returns:
            å±‚æ•°
        """
        try:
            with open(f"workload_inputs/{workload_input}", 'r') as in_file:
                # è·³è¿‡ç¬¬ä¸€è¡Œ
                in_file.readline()
                # è¯»å–å±‚æ•°
                lines = int(in_file.readline().strip())
                return lines
        except FileNotFoundError:
            print(f"æ— æ³•æ‰“å¼€æ–‡ä»¶: {workload_input}")
            sys.exit(1)
        except Exception as e:
            print(f"è¯»å–å±‚æ•°æ—¶å‡ºé”™: {e}")
            sys.exit(1) 